{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = [[1,5,3,7,8,10,12],\n",
    "              [5,8,10,3,9,7,1]]\n",
    "\n",
    "label_data = [[0,0,0,1,0],\n",
    "              [1,0,0,0,0]]\n",
    "\n",
    "INPUT_SIZE = 7\n",
    "HIDDEN1_SIZE = 10\n",
    "HIDDEN2_SIZE = 8\n",
    "CLASSES = 5\n",
    "\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "shape를 정해줄 때에서 법칙이 있는데 첫번째 디멘전이 있고, 두법째 디멘전이 있고, 세번째 디멘전이있고... 등등 쭉 나가는데\n",
    "첫번째 디멘전은 무조건 배치가 들어간다 즉 입력되는 데이터가 몇개인가? 배치사이즈 \n",
    "보통 배치에 개수는 알수 없는 경우가 일반적이다 즉 데이터가 몇개가 정확히 들어올지 모른다. 그래서 1차원 자리는 None로 보통 한다. \n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, INPUT_SIZE]) # 보통 직접 숫자를 써주는 것이 아니라 상수를 이용한다. \n",
    "y_ = tf.placeholder(tf.float32, shape=[None, CLASSES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_map = {x: input_data, y_: label_data} #세션의 두번째 파라미터에 입력을 하는데 이것은 세션을 돌릴때 {x:,y_:}텐서는 위의 input_data와 label_data를 써라 라는 소리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에까지로 보면 인풋데이터 정의 아웃풋데이터 정의 placeholder정의가 준비 되었다 이젠 모델을 설계 하면 된다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망은 인풋데이터들과 곱해질 weight가 필요 하다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#우리는 예전에 variable를 사용할때 tf.Variable([1,2,3]) 이렇게 값을 직접 지정 했지만 실제 사용할때에는 랜덤값으로 한다. \n",
    "#tf.truncated_normal(shape)를 넣는데 이때 리턴되는 결과가 Variable의 shape로 들어간다. \n",
    "W_h1 = tf.Variable(tf.truncated_normal([INPUT_SIZE, HIDDEN1_SIZE]), dtype=tf.float32)\n",
    "\n",
    "#bias라는 것도 중요하다 반드시 넣어줘서 high bias현상을 없애 줘야 한다.\n",
    "b_h1 = tf.Variable(tf.zeros(shape=[HIDDEN1_SIZE]), dtype=tf.float32)\n",
    "\n",
    "W_h2 = tf.Variable(tf.truncated_normal([HIDDEN1_SIZE, HIDDEN2_SIZE]), dtype=tf.float32)\n",
    "b_h2 = tf.Variable(tf.zeros(shape=[HIDDEN2_SIZE]), dtype=tf.float32)\n",
    "\n",
    "W_o = tf.Variable(tf.truncated_normal([HIDDEN2_SIZE, CLASSES]), dtype=tf.float32)\n",
    "b_o = tf.Variable(tf.zeros(shape=[CLASSES]), dtype=tf.float32)\n",
    "\n",
    "\n",
    "#세이브를 할경우 Variable가 끝나는 시점에 생성을 해준다. \n",
    "#saver = tf.train.Saver()  #이렇게 해주면 위에 나오는 Variable는 다 저장 된다.\n",
    "\n",
    "param_list = [W_h1, b_h1, W_h2, b_h2, W_o, b_o]\n",
    "saver = tf.train.Saver(param_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden1 = tf.sigmoid(tf.matmul(x, W_h1) + b_h1)\n",
    "hidden2 = tf.sigmoid(tf.matmul(hidden1, W_h2) + b_h2)\n",
    "y = tf.sigmoid(tf.matmul(hidden2, W_o) + b_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에처럼 하면 모델 설계가 다 된 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sigmoid_2:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트레이닝을 시키기 위해서는 cost function이 필요하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#크로스 엔트로피!\n",
    "cost = tf.reduce_mean(tf.reduce_sum(-y_ * tf.log(y) - (1-y_) * tf.log(1-y), reduction_indices=1))  # y_이 0일경우에는 (1-y_)*tf.log(1-y) 가 돌게 한다. \n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp_pred = tf.equal(tf.arg_max(y, 1), tf.arg_max(y_, 1))\n",
    "accurcy = tf.reduce_mean(tf.cast(comp_pred, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0  loss:  6.29402  acc:  0.0\n",
      "step:  100  loss:  2.52943  acc:  0.5\n",
      "step:  200  loss:  1.83996  acc:  0.5\n",
      "step:  300  loss:  1.55292  acc:  1.0\n",
      "step:  400  loss:  1.37556  acc:  1.0\n",
      "step:  500  loss:  1.23686  acc:  1.0\n",
      "step:  600  loss:  1.11499  acc:  1.0\n",
      "step:  700  loss:  1.00496  acc:  1.0\n",
      "step:  800  loss:  0.906505  acc:  1.0\n",
      "step:  900  loss:  0.819279  acc:  1.0\n",
      "step:  1000  loss:  0.742331  acc:  1.0\n",
      "step:  1100  loss:  0.674484  acc:  1.0\n",
      "step:  1200  loss:  0.614614  acc:  1.0\n",
      "step:  1300  loss:  0.561725  acc:  1.0\n",
      "step:  1400  loss:  0.51495  acc:  1.0\n",
      "step:  1500  loss:  0.473529  acc:  1.0\n",
      "step:  1600  loss:  0.436792  acc:  1.0\n",
      "step:  1700  loss:  0.40415  acc:  1.0\n",
      "step:  1800  loss:  0.375085  acc:  1.0\n",
      "step:  1900  loss:  0.349142  acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(2000):\n",
    "    _, cost_val, acc = sess.run([train, cost, accurcy], feed_dict=tensor_map)  #여기서 train과 cost는 따로 실행이 된다. 서로 연관된게 아니다. \n",
    "    if i % 100 == 0:\n",
    "        saver.save(sess, \"./tenserflow_live.ckpt\")\n",
    "        print(\"step: \", i, \" loss: \", cost_val, \" acc: \", acc)\n",
    "\n",
    "sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
